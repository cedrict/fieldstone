\noindent
\includegraphics[height=1.25cm]{images/pictograms/benchmark}
\includegraphics[height=1.25cm]{images/pictograms/FEM}
\includegraphics[height=1.25cm]{images/pictograms/paraview}
\includegraphics[height=1.25cm]{images/pictograms/clean}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\lstinputlisting[language=bash,basicstyle=\small]{python_codes/fieldstone_16/keywords.ascii}

\begin{center}
\inpython \hspace{.5cm}
{\small Code at \url{https://github.com/cedrict/fieldstone/tree/master/python_codes/fieldstone_16}}
\end{center}

\par\noindent\rule{\textwidth}{0.4pt}

Last revision: Sept. 8th, 2024.

\par\noindent\rule{\textwidth}{0.4pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We are revisiting the 2D Stokes sphere problem, but this time 
we use the Schur complement approach to solve the Stokes system. 
We choose an open boundary at the top so that we do not have to deal with the pressure 
nullspace. No-slip boundary conditions are prescribed on the sides and bottom boundaries.
Density is prescribed directly onto the quadrature points. 

Because there are viscosity contrasts in the domain, it is advisable 
to use the Preconditioned Conjugate Gradient 
as presented in Section \ref{MMM-sec:solvers} (see {\bf solver\_pcg}).\\
The solver is implemented in the {\tt schur\_complement\_cg\_solver.py} file in the same folder.  

\begin{center} 
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/eta}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/vel}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/exx}\\
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/rho}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/q}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/exy}\\
{\captionfont Viscosity, density, velocity and pressure fields, resolution $96\times 96$.}
\end{center} 

\begin{center} 
\includegraphics[width=5cm]{python_codes/fieldstone_16/results/visc_field_1/matrix_ps2}
\includegraphics[width=5cm]{python_codes/fieldstone_16/results/visc_field_1/matrix_ps3}\\
{\captionfont Resolution 8x8 elements. Matrix sparsity pattern 
for preconditioner \#2 (left) and preconditioners 0,1,3,4 (right).}
\end{center}



\noindent We have designed 5 preconditioners. 
The preconditioners have to be similar to the Schur complement $\SSS=\G^T \cdot \K^{-1} \cdot \G$.
These matrices are of size $Nfem_P \times Nfem_P$:
\begin{lstlisting}
M_mat=np.zeros((Nfem_P,Nfem_P),dtype=np.float64) # preconditioner 
\end{lstlisting}


\begin{itemize}

\item \lstinline{precond_type=0} It is the unit matrix (so it does nothing). 
This translates as follows:
\begin{lstlisting}
for i in range(0,Nfem_P):
    M_mat[i,i]=1
\end{lstlisting}


\item \lstinline{precond_type=1} This is a very simple one as it is diagonal and built element by element:
\[
\M_{e,e} = \frac{h_x h_y}{\eta_e} 
\]
where $e$ is an element and $\eta_e$ the viscosity evaluated in its center. Note that 
averages based on quadrature point values could also be considered (or any other kind of projection).
This translates as follows:
\begin{lstlisting}
for iel in range(0,nel):
    M_mat[iel,iel]=hx*hy/eta_e[iel]
\end{lstlisting}


\item \lstinline{precond_type=2}
\[
{\M} = \G^T (\text{diag} [\K]  )^{-1} \G 
\]
This translates as follows:
\begin{lstlisting}
Km1=np.zeros((Nfem_V,Nfem_V),dtype=np.float64) 
for i in range(0,Nfem_V):
    Km1[i,i]=1./K_mat[i,i] 
M_mat=G_mat.T.dot(Km1.dot(G_mat))
\end{lstlisting}
Note that this preconditioner is currently built using the assembled $\K$ and $\G$ matrices.
I could/should think of a more economical way of building it. However one can show (tedious!)
that it cannot be built at the elemental level and then assembled. 

Note also that I have tried to use a version of the $\G$ matrix which 
is assembled from the elemental $\G_e$ matrices {\it before} boundary conditions 
are applied (the $\K$ matrix diagonal is unaffected by the 
boundary conditions). The convergence is much worse. 

Finally, since each outer iteration in the solver contains a solve 
with $\K$ and $\M$, we could think of resorting to using an LU
decomposition (see \stone~147). In this case we would replace 
\begin{lstlisting}
solV=sps.linalg.spsolve(K_mat,f_rhs)
\end{lstlisting}
by
\begin{lstlisting}
LU = sla.splu(K_mat)
solV=LU.solve(f_rhs)
\end{lstlisting}
followed by 
\begin{lstlisting}
dvect_k=LU.solve(G_mat.dot(pvect_k)) 
\end{lstlisting}
inside the iterations. The same would go for the application
of the preconditioner. 
The single LU decomposition of both matrices at the beginning 
have a cost but the subsequent solves become really cheap. 

This is implemented in {\tt schur\_complement\_cg\_solver\_LU.py}.
 

\item \lstinline{precond_type=3} 
\[
{\M} = diag \left[ \G^T (diag [\K]  )^{-1} \G \right]
\]

This translates as follows:
\begin{lstlisting}
   Km1=np.zeros((Nfem_V,Nfem_V),dtype=np.float64) 
   for i in range(0,Nfem_V):
       Km1[i,i]=1./K_mat[i,i] 
   M_mat=G_mat.T.dot(Km1.dot(G_mat))
   for i in range(0,Nfem_P):
       for j in range(0,Nfem_P):
           if i!=j:
              M_mat[i,j]=0.
\end{lstlisting}




\item \lstinline{precond_type=4} Same as 2, but instead of using the 
diagonal of $ \G^T (diag [\K]  )^{-1} \G$ we lump the matrix instead.
This translates as follows:


\begin{lstlisting}
   Km1    = np.zeros((Nfem_V,Nfem_V),dtype=np.float64) 
   for i in range(0,Nfem_V):
       Km1[i,i]=1./K_mat[i,i] 
   M_mat=G_mat.T.dot(Km1.dot(G_mat))
   for i in range(0,Nfem_P):
       for j in range(0,Nfem_P):
           if i!=j:
              M_mat[i,i]+=np.abs(M_mat[i,j])
              M_mat[i,j]=0.
\end{lstlisting}




\end{itemize}

\noindent There are also multiple ways to prescribe the viscosity on the quadrature points:
\begin{itemize}
\item \lstinline{viscosity_field=1}: viscosity is directly computed 
on the quadrature points;
\item \lstinline{viscosity_field=2}: viscosity is elemental;
\item \lstinline{viscosity_field=3}: viscosity is assigned to nodes and then 
interpolated onto quadrature points with an arithmetic averaging;
\item \lstinline{viscosity_field=4}: viscosity is assigned to nodes and then 
interpolated onto quadrature points with a geometric averaging;
\item \lstinline{viscosity_field=5}: viscosity is assigned to nodes and then 
interpolated onto quadrature points with a harmonic averaging.
\end{itemize}

\newpage







%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsubsection{viscosity\_field=1}

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_1/residual_32x32.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_1/residual_64x64.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_1/residual_96x96.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_1/residual_128x128.pdf}\\
{\captionfont viscosity\_field=1: Residual inside the solver as a function of the preconditioner type for
4 mesh resolutions.}
\end{center}

\begin{center} 
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/niterations.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/solve_time.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_1/build_precond.pdf}\\
{\captionfont viscosity\_field=1: Left: Number of iterations inside the solver; 
Middle: time spent in the solver.
Right: time spent to build the preconditioner matrix.}
\end{center} 

Conclusion: preconditioner \#2 is the best: less outer iterations, fastest solve. 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{viscosity\_field=2}

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_2/residual_32x32.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_2/residual_64x64.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_2/residual_96x96.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_2/residual_128x128.pdf}\\
{\captionfont viscosity\_field=2: Residual inside the solver as a function of the preconditioner type for
4 mesh resolutions.}
\end{center}

\begin{center} 
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_2/niterations.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_2/solve_time.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_2/build_precond.pdf}\\
{\captionfont viscosity\_field=2: Left: Number of iterations inside the solver; 
Middle: time spent in the solver.
Right: time spent to build the preconditioner matrix.
}\end{center} 

Conclusion: preconditioner \#2 is the best: less outer iterations, fastest solve. 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{viscosity\_field=3}

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_3/residual_32x32.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_3/residual_64x64.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_3/residual_96x96.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_3/residual_128x128.pdf}\\
{\captionfont viscosity\_field=3: Residual inside the solver as a function of the preconditioner type for
4 mesh resolutions.}
\end{center}

\begin{center} 
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_3/niterations.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_3/solve_time.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_3/build_precond.pdf}\\
{\captionfont viscosity\_field=3: Left: Number of iterations inside the solver; 
Middle: time spent in the solver.
Right: time spent to build the preconditioner matrix.}
\end{center} 

Conclusion: preconditioner \#2 is the best: less outer iterations, fastest solve. 




\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{viscosity\_field=4}

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_4/residual_32x32.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_4/residual_64x64.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_4/residual_96x96.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_4/residual_128x128.pdf}\\
{\captionfont viscosity\_field=4: Residual inside the solver as a function of the preconditioner type for
4 mesh resolutions.}
\end{center}


\begin{center} 
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_4/niterations.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_4/solve_time.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_4/build_precond.pdf}\\
{\captionfont viscosity\_field=4: Left: Number of iterations inside the solver; 
Middle: time spent in the solver.
Right: time spent to build the preconditioner matrix.}
\end{center} 

Conclusion: preconditioner \#2 is the best: less outer iterations, fastest solve. 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{viscosity\_field=5}

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_5/residual_32x32.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_5/residual_64x64.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_5/residual_96x96.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_5/residual_128x128.pdf}\\
{\captionfont viscosity\_field=5: Residual inside the solver as a function of the preconditioner type for
4 mesh resolutions.}
\end{center}

\begin{center} 
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_5/niterations.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_5/solve_time.pdf}
\includegraphics[width=5.7cm]{python_codes/fieldstone_16/results/visc_field_5/build_precond.pdf}\\
{\captionfont viscosity\_field=5: Left: Number of iterations inside the solver; 
Middle: time spent in the solver.
Right: time spent to build the preconditioner matrix.}
\end{center} 

Conclusion: preconditioner \#2 is the best: less outer iterations, fastest solve. 

\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

On can also plot these same results (here the number of iterations in the outer solver), 
but this time per preconditioner type:

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/niterations_ps0.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/niterations_ps1.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/niterations_ps2.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/niterations_ps3.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/niterations_ps4.pdf}
\end{center}


\newpage
On can also plot these same results (here the solve time), 
but this time per preconditioner type:

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/solve_time_ps0.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/solve_time_ps1.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/solve_time_ps2.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/solve_time_ps3.pdf}\\
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/solve_time_ps4.pdf}
\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Using an LU decomposition for K and M}

We find that this makes a huge difference in the solve time. Using an LU solver 
for both $\K$ and $\M$ yields a solver that is about 10x faster! 
This is controlled by the \lstinline{use_LU} flag.

\begin{center} 
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_2/ILU/solve_time.pdf}
\includegraphics[width=8cm]{python_codes/fieldstone_16/results/visc_field_2/ILU/residual.pdf}\\
{\captionfont results obtained with precond \#2 and viscosity field 2.}
\end{center}





\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Conclusion}

These figures essentially prove in a rather concrete way why the $Q_1\times P_0$ element 
is not an element which should be used: the number of outer iterations grows with the 
number of elements while each iteration itself becomes more costly because the size of the 
matrix $\K$ increases too.

We see that the choice of preconditioner is important. Preconditioner \#2 gives the best 
and most predictable results but its preconditioner matrix is not diagonal so that 
its use implies solving with it at each solver iteration, which has a cost: although at 
resolution $96\times 96$ it requires the least iterations, the total time spent in the solver does
not reflect this fact as well. It is also expensive to build! 

Finally preconditioners \#3 and \#4 show extremely similar results, with a little 
advantage for \#3, i.e. lumping does not help at all.

Since we have used the python solver as a black box inside our solver for $\K$ and ${\M}$
there would be much more to look into in this direction. I do so in \stone~147.

\begin{remark}
I have tried lil\_matrix and csr format on the $\K$, $\G$ and $\M$ matrices 
but it makes the times to build these explode, so I stick to full matrices. 
\end{remark}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{Can we build the preconditioner 2 faster?}

Let us consider a 3x2 mesh. We have 6 elements and 12 nodes, so that 
\lstinline{NfemV=24} and \lstinline{NfemP=6}. The sparsity pattern 
of the $\M$ matrix is as follows:

\includegraphics[width=5cm]{python_codes/fieldstone_16/images/matrix_3x2}

We see that the non zeros are placed where two elements share a node.
\begin{itemize}
\item 
Line 0 reads: element 0 shares a node with elements 0, 1, 3, 4.
\item 
Line 1 reads: element 1 shares a node with elements 0, 1, 2, 3, 4, 5.
\item 
Line 2 reads: element 2 shares a node with elements 1, 2, 4, 5.
\item 
Line 3 reads: element 3 shares a node with elements 0, 1, 3, 4. 
\item 
Line 4 reads: element 4 shares a node with elements 0, 1, 2, 3, 4, 5.
\item 
Line 5 reads: element 5 shares a node with elements 1, 2, 4, 5.  
\end{itemize}



\begin{landscape}

We wish to compute 
\[
\M = \G^T \cdot (\text{diag}(\K))^{-1} \cdot \G
\]
The non zero pattern of the $\G^T$ matrix is given by (in what follows $G_{i,j}$ is actually $\G^T$):
\begin{tiny}
\[
\G^T=
\left(
\begin{array}{cccccccccccccccccccccccc}
G_{0,0} & G_{0,1} & G_{0,2} & G_{0,3} & 0 & 0 & 0 & 0 & G_{0,8} & G_{0,9} & G_{0,10} & G_{0,11} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \\
0 & 0 & G_{1,2} & G_{1,3} & G_{1,4} & G_{1,5} & 0 & 0 & 0 & 0 & G_{1,10} & G_{1,11} & G_{1,12} & G_{1,13} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \\
0 & 0 & 0 & 0 & G_{2,4} & G_{2,5} & G_{2,6} & G_{2,7} & 0 & 0 & 0 & 0 & G_{2,12} & G_{2,13} & G_{2,14} & G_{2,15} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & G_{3,8} & G_{3,9} & G_{3,10} & G_{3,11} & 0 & 0 & 0 & 0 & G_{3,16} & G_{3,17} & G_{3,18} & G_{3,19} & 0 & 0 & 0 & 0 \\ \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & G_{4,10} & G_{4,11} & G_{4,12} & G_{4,13} & 0 & 0 & 0 & 0 & G_{4,18} & G_{4,19} & G_{4,20} & G_{4,21} & 0 & 0 \\ \\
0 & 0 & 00 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & G_{5,12} & G_{5,13} & G_{5,14} & G_{5,15} & 0 & 0 & 0 & 0 & G_{5,20} & G_{5,21} & G_{5,22} & G_{5,23}  \\ \\
\end{array}
\right)
\]
and
\[
\G=
\left(
\begin{array}{cccccc}
G_{0,0} &  0 & 0 & 0 & 0 & 0 \\
G_{0,1} &  0 & 0 & 0 & 0 & 0 \\
G_{0,2} &  G_{1,2} & 0 & 0 & 0 & 0 \\
G_{0,3} &  G_{1,3} & 0 & 0 & 0 & 0 \\
0 & G_{1,4} &  G_{2,4} & 0 & 0 & 0 \\
0 & G_{1,5} &  G_{2,5} & 0 & 0 & 0 \\
0 & 0 &  G_{2,6} & 0 & 0 & 0 \\
0 & 0 &  G_{2,7} & 0 & 0 & 0 \\
G_{0,8} & 0 & 0& G_{3,8} &0&0 \\
G_{0,9} & 0 & 0& G_{3,9}&0&0 \\
G_{0,10} & G_{1,10} & 0& G_{3,10}& G_{4,10}&0 \\
G_{0,11} & G_{1,11} & 0& G_{3,11} & G_{4,11}&0\\
0 & G_{1,12}& G_{2,12} & 0& G_{4,12}& G_{5,12}\\
0 & G_{1,13}& G_{2,13} & 0& G_{4,13}& G_{5,13}\\
0 & 0& G_{2,14}&0& 0& G_{5,14}\\ 
0 & 0& G_{2,15}&0& 0& G_{5,15}\\
0 & 0& 0& G_{3,16}& 0& 0\\
0 & 0& 0& G_{3,17}& 0& 0\\
0 & 0& 0&G_{3,18}& G_{4,18}& 0\\
0 & 0& 0& G_{3,19}& G_{4,19}& 0\\
0 & 0& 0& 0 & G_{4,20} & G_{5,20} \\
0 & 0& 0& 0 & G_{4,21} & G_{5,21} \\
0 & 0& 0& 0 & 0 & G_{5,22}  \\
0 & 0& 0& 0 & 0 & G_{5,23} 
\end{array}
\right)
\]
\end{tiny}
Note that I have not taken the zeroed lines coming from the boundary conditions into account.
Let us define $\tilde{\K}=\text{diag}(\K)^{-1}$. Since $\tilde{\K}$ is diagonal I will only use a single 
subscript to index its components in what follows. 
The matrix $\M$ is obviously symmetric. I start with the the diagonal terms:
\begin{eqnarray}
M_{0,0} &=& 
G_{0,0}^2 \tilde{K}_0 + G_{0,1}^2 \tilde{K}_1 + G_{0,2}^2 \tilde{K}_2 + G_{0,3}^2 \tilde{K}_3 + 
G_{0,8}^2 \tilde{K}_8 + G_{0,9}^2 \tilde{K}_9 + G_{0,10}^2 \tilde{K}_{10} + G_{0,11}^2 \tilde{K}_{11} \nn\\
M_{1,1} &=&  
G_{1,2}^2 \tilde{K}_2 + G_{1,3}^2 \tilde{K}_3 + G_{1,4}^2 \tilde{K}_4 + G_{1,5}^2 \tilde{K}_5 + 
G_{1,10}^2 \tilde{K}_{10} + G_{1,11}^2 \tilde{K}_{11} + G_{1,12}^2 \tilde{K}_{12} + G_{1,13}^2 \tilde{K}_{13} \nn\\
M_{2,2} &=&  
G_{2,4}^2 \tilde{K}_4 + G_{2,5}^2 \tilde{K}_5 + G_{2,6}^2 \tilde{K}_6 + G_{2,7}^2 \tilde{K}_7 + 
G_{2,12}^2 \tilde{K}_{12} + G_{2,13}^2 \tilde{K}_{13} + G_{2,14}^2 \tilde{K}_{14} + G_{2,15}^2 \tilde{K}_{15} \nn\\
M_{3,3} &=& etc... \nn\\
M_{4,4} &=& etc... \nn\\
M_{5,5} &=& etc... \nn
\end{eqnarray}
In the end the diagonal terms can be computed as follows:
\[
M_{e,e}=\sum_{j} G_{e,j}^2 \tilde{K}_j
\]
where $j$ runs over the velocity dofs of the nodes making the element $e$.

Let us now turn to the off/upper-diagonal terms:
\begin{eqnarray}
M_{0,1} &=&  G_{0,2} G_{1,2} \tilde{K}_2 + G_{0,3} G_{1,3} \tilde{K}_3 
+ G_{0,10} G_{1,10} \tilde{K}_{10} + G_{0,11} G_{1,11} \tilde{K}_{11} \nn\\
M_{0,2} &=& 0 \nn\\
M_{0,3} &=& G_{0,8}G_{3,8} \tilde{K}_8 + G_{0,9}G_{3,9} \tilde{K}_9 + G_{0,10}G_{3,10} \tilde{K}_{10} + G_{0,11}G_{3,11} \tilde{K}_{11} \nn\\
M_{0,4} &=& ...\nn
\end{eqnarray}

Here too a pattern emerges. 
\[
M_{e,e'}=\sum_{j} G_{e,j} G_{e',j} \tilde{K}_j
\]
where $j$ runs over the dofs common to elements $e$ and $e'$.
And we also see that the diagonal terms expression is a simplified expression of the one above.

In conclusion, we see that the non-zero structure of $\M$ is easy to compute, and there is also a way to fill $\M$ 
by means of a loop rather than multiplying fully assembled matrices containing mostly zeros.
My guess is that one must first compute the list of elements a node belongs to, and then proceed to loop 
over all nodes and add contributions to $\M$. 
Since I do not really need a fast version of this algorithm I leave it there for now.

\end{landscape}







